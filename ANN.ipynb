{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynzUllbQB2Rl"
      },
      "source": [
        "*   The Fashion MNIST database has a database of fashion accessories.\n",
        "\n",
        "*   Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747, 2017.\n",
        "\n",
        "*   The training set has  60,000  samples. The test set has  10,000  samples.\n",
        "\n",
        "*   The fashion accessories are size-normalized and centered in a fixed-size image.\n",
        "\n",
        "*   We will train Multi-layer Perceptron using Keras for Fashion MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dvl-r1HABPQA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HmVX6vQbCFEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf679e3f-a80c-446c-d06a-5ee81bcf6b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO4h9mcHCpkq"
      },
      "source": [
        "** Visualize the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z3BfHegJC9Hm"
      },
      "outputs": [],
      "source": [
        "img_rows, img_cols =28,28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-XY6SifzDB4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45068dbc-fbd6-4c50-822f-b804bf57de69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "# MLP\n",
        "X_train_mlp = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
        "Y_train_mlp_1 = Y_train\n",
        "\n",
        "X_test_mlp = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
        "Y_test_mlp_1 = Y_test\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k889bERwCbbv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "511558e3-cc91-4746-e336-733c99792932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (60000, 28, 28) Y_train shape: (60000,)\n",
            "Y = 2 Pullover\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa57f738d00>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
        "print(\"X_train shape:\", X_train.shape, \"Y_train shape:\", Y_train.shape)\n",
        "\n",
        "# Define the labels\n",
        "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
        "                        \"Trouser\",      # index 1\n",
        "                        \"Pullover\",     # index 2\n",
        "                        \"Dress\",        # index 3\n",
        "                        \"Coat\",         # index 4\n",
        "                        \"Sandal\",       # index 5\n",
        "                        \"Shirt\",        # index 6\n",
        "                        \"Sneaker\",      # index 7\n",
        "                        \"Bag\",          # index 8\n",
        "                        \"Ankle boot\"]   # index 9\n",
        "\n",
        "# Image index, you can pick any number between 0 and 59,999\n",
        "img_index = 5\n",
        "\n",
        "# y_train contains the lables, ranging from 0 to 9\n",
        "label_index = Y_train[img_index]\n",
        "\n",
        "# Print the label, for example 2 Pullover\n",
        "print (\"Y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
        "\n",
        "# # Show one of the images from the training dataset\n",
        "plt.imshow(X_train[img_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UaITN7ikDk-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36514cae-aab3-41cf-df3b-7d479e9caea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_mlp.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tV7ht-OjC_J0"
      },
      "outputs": [],
      "source": [
        "X_train_mlp = X_train_mlp.astype('float32')\n",
        "X_test_mlp = X_test_mlp.astype('float32')\n",
        "X_train_mlp /= 255\n",
        "X_test_mlp /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bdO9Dl08EO3p"
      },
      "outputs": [],
      "source": [
        "# Convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "\n",
        "Y_train_mlp = keras.utils.to_categorical(Y_train_mlp_1, num_classes)\n",
        "\n",
        "Y_test_mlp = keras.utils.to_categorical(Y_test_mlp_1,num_classes )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KM-qNaGpEcMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f403786-d76f-490e-b2a5-823bb9877a7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "Y_train_mlp[:5,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C1LezZKuEgRy"
      },
      "outputs": [],
      "source": [
        "# Split data to optimize classifier during training\n",
        "X_train_mlp, X_val_mlp, Y_train_mlp, Y_val_mlp = train_test_split(X_train_mlp,\n",
        "                                                                  Y_train_mlp,\n",
        "                                                                  test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A60Al_34Erih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc76f67-7fdc-433d-943f-1d5f18eef618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_mlp.shape)\n",
        "print(X_val_mlp.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1D1UQ8_Ezf6"
      },
      "source": [
        "#**Multi Layer Perceptron**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CkDSbfGoE1OR"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yi-AoA6zE4NI"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E_m9kNVBE5Qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64b22a3-dc45-4c19-9369-bcee5f233b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 625)               490625    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                6260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 496,885\n",
            "Trainable params: 496,885\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Multilayer Perceptron model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(input_dim=784, activation='sigmoid', units=625, kernel_initializer='normal'))\n",
        "\n",
        "model.add(Dense(input_dim=625, activation='softmax', units=10, kernel_initializer='normal'))\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PE-W5SHZFByJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbdf931-98b3-416d-f8f7-747c46ad7afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 4s 5ms/step - loss: 1.3913 - accuracy: 0.6219 - val_loss: 0.9931 - val_accuracy: 0.6921\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8623 - accuracy: 0.7342 - val_loss: 0.7900 - val_accuracy: 0.7418\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7360 - accuracy: 0.7546 - val_loss: 0.7080 - val_accuracy: 0.7518\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6743 - accuracy: 0.7680 - val_loss: 0.6542 - val_accuracy: 0.7714\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6345 - accuracy: 0.7812 - val_loss: 0.6209 - val_accuracy: 0.7807\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6066 - accuracy: 0.7897 - val_loss: 0.5982 - val_accuracy: 0.7886\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5844 - accuracy: 0.7972 - val_loss: 0.5814 - val_accuracy: 0.7938\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5662 - accuracy: 0.8026 - val_loss: 0.5610 - val_accuracy: 0.8005\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5517 - accuracy: 0.8076 - val_loss: 0.5463 - val_accuracy: 0.8073\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5397 - accuracy: 0.8121 - val_loss: 0.5341 - val_accuracy: 0.8136\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5289 - accuracy: 0.8163 - val_loss: 0.5276 - val_accuracy: 0.8158\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5197 - accuracy: 0.8186 - val_loss: 0.5182 - val_accuracy: 0.8170\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.8215 - val_loss: 0.5106 - val_accuracy: 0.8208\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5053 - accuracy: 0.8236 - val_loss: 0.5038 - val_accuracy: 0.8236\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.8266 - val_loss: 0.4955 - val_accuracy: 0.8262\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4929 - accuracy: 0.8283 - val_loss: 0.4953 - val_accuracy: 0.8210\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4881 - accuracy: 0.8305 - val_loss: 0.4884 - val_accuracy: 0.8283\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4835 - accuracy: 0.8318 - val_loss: 0.4845 - val_accuracy: 0.8304\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4790 - accuracy: 0.8327 - val_loss: 0.4795 - val_accuracy: 0.8346\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4750 - accuracy: 0.8346 - val_loss: 0.4810 - val_accuracy: 0.8307\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4711 - accuracy: 0.8352 - val_loss: 0.4748 - val_accuracy: 0.8318\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4674 - accuracy: 0.8378 - val_loss: 0.4670 - val_accuracy: 0.8353\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4643 - accuracy: 0.8381 - val_loss: 0.4651 - val_accuracy: 0.8357\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4612 - accuracy: 0.8398 - val_loss: 0.4613 - val_accuracy: 0.8377\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4584 - accuracy: 0.8400 - val_loss: 0.4663 - val_accuracy: 0.8321\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4556 - accuracy: 0.8414 - val_loss: 0.4551 - val_accuracy: 0.8397\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4526 - accuracy: 0.8430 - val_loss: 0.4638 - val_accuracy: 0.8357\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.8437 - val_loss: 0.4498 - val_accuracy: 0.8428\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4469 - accuracy: 0.8439 - val_loss: 0.4535 - val_accuracy: 0.8409\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4450 - accuracy: 0.8460 - val_loss: 0.4491 - val_accuracy: 0.8414\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4428 - accuracy: 0.8456 - val_loss: 0.4453 - val_accuracy: 0.8430\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.8461 - val_loss: 0.4432 - val_accuracy: 0.8448\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4392 - accuracy: 0.8473 - val_loss: 0.4434 - val_accuracy: 0.8445\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4371 - accuracy: 0.8475 - val_loss: 0.4395 - val_accuracy: 0.8462\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4355 - accuracy: 0.8482 - val_loss: 0.4360 - val_accuracy: 0.8490\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.8496 - val_loss: 0.4399 - val_accuracy: 0.8460\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.8500 - val_loss: 0.4373 - val_accuracy: 0.8453\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4305 - accuracy: 0.8495 - val_loss: 0.4311 - val_accuracy: 0.8491\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4286 - accuracy: 0.8505 - val_loss: 0.4331 - val_accuracy: 0.8489\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4270 - accuracy: 0.8502 - val_loss: 0.4331 - val_accuracy: 0.8478\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4254 - accuracy: 0.8514 - val_loss: 0.4361 - val_accuracy: 0.8435\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4240 - accuracy: 0.8511 - val_loss: 0.4285 - val_accuracy: 0.8497\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4227 - accuracy: 0.8530 - val_loss: 0.4292 - val_accuracy: 0.8502\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4212 - accuracy: 0.8529 - val_loss: 0.4281 - val_accuracy: 0.8497\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8535 - val_loss: 0.4320 - val_accuracy: 0.8467\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8526 - val_loss: 0.4384 - val_accuracy: 0.8413\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8542 - val_loss: 0.4226 - val_accuracy: 0.8508\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4163 - accuracy: 0.8546 - val_loss: 0.4221 - val_accuracy: 0.8513\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8544 - val_loss: 0.4227 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4139 - accuracy: 0.8550 - val_loss: 0.4186 - val_accuracy: 0.8539\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train_mlp,Y_train_mlp,\n",
        "          batch_size = batch_size,\n",
        "          epochs = num_epochs,\n",
        "          verbose = 1,\n",
        "          validation_data = (X_val_mlp,Y_val_mlp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VPY2NCaVGGb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1120c570-1cd0-468e-e9a7-0c4eebcb667f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.8376\n",
            "\n",
            "MLP Test loss: 0.450467586517334\n",
            "MLP Test accuracy: 0.8375999927520752\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test_mlp, Y_test_mlp, verbose = 1)\n",
        "print()\n",
        "print('MLP Test loss:', score[0])\n",
        "print('MLP Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "eqrCQbtz71fY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2_4fKqsVGOMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbaa5d6c-1e77-4b40-95b2-24c74d22aaa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 625)               490625    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 625)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 625)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 625)               391250    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 625)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 625)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 625)               391250    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 625)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 625)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 625)               391250    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 625)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,664,375\n",
            "Trainable params: 1,664,375\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Deep Multilayer Perceptron model\n",
        "model_deepmlp = Sequential()\n",
        "\n",
        "model_deepmlp.add(Dense(input_dim=784, units=625, kernel_initializer='normal'))\n",
        "model_deepmlp.add(Activation('relu'))\n",
        "model_deepmlp.add(Dropout(0.2))\n",
        "\n",
        "model_deepmlp.add(Dense(input_dim=625, units=625, kernel_initializer='normal'))\n",
        "model_deepmlp.add(Activation('relu'))\n",
        "model_deepmlp.add(Dropout(0.2))\n",
        "\n",
        "model_deepmlp.add(Dense(input_dim=625, units=625, kernel_initializer='normal'))\n",
        "model_deepmlp.add(Activation('relu'))\n",
        "model_deepmlp.add(Dropout(0.2))\n",
        "\n",
        "model_deepmlp.add(Dense(input_dim=625, units=625, kernel_initializer='normal'))\n",
        "model_deepmlp.add(Activation('softmax'))\n",
        "\n",
        "model_deepmlp.compile(optimizer=RMSprop(lr=0.001, rho=0.9),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_deepmlp.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o9qfpzENGSg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9971647-64d2-4fa8-d9ed-22d787bd3de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4127 - accuracy: 0.8552 - val_loss: 0.4185 - val_accuracy: 0.8522\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8558 - val_loss: 0.4179 - val_accuracy: 0.8533\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8564 - val_loss: 0.4182 - val_accuracy: 0.8530\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8569 - val_loss: 0.4205 - val_accuracy: 0.8516\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4078 - accuracy: 0.8569 - val_loss: 0.4157 - val_accuracy: 0.8534\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4075 - accuracy: 0.8573 - val_loss: 0.4124 - val_accuracy: 0.8555\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4061 - accuracy: 0.8576 - val_loss: 0.4151 - val_accuracy: 0.8537\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4048 - accuracy: 0.8578 - val_loss: 0.4129 - val_accuracy: 0.8558\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4039 - accuracy: 0.8580 - val_loss: 0.4423 - val_accuracy: 0.8393\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4030 - accuracy: 0.8586 - val_loss: 0.4108 - val_accuracy: 0.8551\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4019 - accuracy: 0.8592 - val_loss: 0.4101 - val_accuracy: 0.8559\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4005 - accuracy: 0.8600 - val_loss: 0.4090 - val_accuracy: 0.8553\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3999 - accuracy: 0.8603 - val_loss: 0.4080 - val_accuracy: 0.8570\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3993 - accuracy: 0.8596 - val_loss: 0.4132 - val_accuracy: 0.8545\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3981 - accuracy: 0.8607 - val_loss: 0.4104 - val_accuracy: 0.8558\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3972 - accuracy: 0.8607 - val_loss: 0.4069 - val_accuracy: 0.8579\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3962 - accuracy: 0.8615 - val_loss: 0.4098 - val_accuracy: 0.8554\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3956 - accuracy: 0.8609 - val_loss: 0.4046 - val_accuracy: 0.8572\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.3947 - accuracy: 0.8607 - val_loss: 0.4063 - val_accuracy: 0.8564\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.3934 - accuracy: 0.8624 - val_loss: 0.4081 - val_accuracy: 0.8548\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3927 - accuracy: 0.8615 - val_loss: 0.4142 - val_accuracy: 0.8542\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3917 - accuracy: 0.8624 - val_loss: 0.4020 - val_accuracy: 0.8588\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3910 - accuracy: 0.8629 - val_loss: 0.4048 - val_accuracy: 0.8568\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3897 - accuracy: 0.8635 - val_loss: 0.4025 - val_accuracy: 0.8577\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3894 - accuracy: 0.8630 - val_loss: 0.4104 - val_accuracy: 0.8545\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3884 - accuracy: 0.8642 - val_loss: 0.4018 - val_accuracy: 0.8587\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3880 - accuracy: 0.8636 - val_loss: 0.4001 - val_accuracy: 0.8581\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3870 - accuracy: 0.8639 - val_loss: 0.3976 - val_accuracy: 0.8615\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3858 - accuracy: 0.8639 - val_loss: 0.3971 - val_accuracy: 0.8609\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3855 - accuracy: 0.8651 - val_loss: 0.3969 - val_accuracy: 0.8616\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3849 - accuracy: 0.8645 - val_loss: 0.3977 - val_accuracy: 0.8602\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3836 - accuracy: 0.8651 - val_loss: 0.3952 - val_accuracy: 0.8623\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3836 - accuracy: 0.8652 - val_loss: 0.3936 - val_accuracy: 0.8618\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3819 - accuracy: 0.8660 - val_loss: 0.3988 - val_accuracy: 0.8608\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.3816 - accuracy: 0.8648 - val_loss: 0.3973 - val_accuracy: 0.8597\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.3807 - accuracy: 0.8658 - val_loss: 0.4063 - val_accuracy: 0.8575\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.3802 - accuracy: 0.8660 - val_loss: 0.3939 - val_accuracy: 0.8620\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3793 - accuracy: 0.8669 - val_loss: 0.3930 - val_accuracy: 0.8617\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3788 - accuracy: 0.8668 - val_loss: 0.3943 - val_accuracy: 0.8605\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3776 - accuracy: 0.8679 - val_loss: 0.3920 - val_accuracy: 0.8621\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.8673 - val_loss: 0.3984 - val_accuracy: 0.8576\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3765 - accuracy: 0.8674 - val_loss: 0.3909 - val_accuracy: 0.8626\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8668 - val_loss: 0.3922 - val_accuracy: 0.8628\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8673 - val_loss: 0.3908 - val_accuracy: 0.8619\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3741 - accuracy: 0.8676 - val_loss: 0.3927 - val_accuracy: 0.8613\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8679 - val_loss: 0.3917 - val_accuracy: 0.8617\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.8691 - val_loss: 0.3919 - val_accuracy: 0.8608\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3723 - accuracy: 0.8693 - val_loss: 0.3858 - val_accuracy: 0.8639\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3711 - accuracy: 0.8689 - val_loss: 0.3856 - val_accuracy: 0.8656\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3705 - accuracy: 0.8697 - val_loss: 0.3866 - val_accuracy: 0.8629\n"
          ]
        }
      ],
      "source": [
        "history_deepmlp = model.fit(X_train_mlp,Y_train_mlp,\n",
        "          batch_size = batch_size,\n",
        "          epochs = num_epochs,\n",
        "          verbose = 1,\n",
        "          validation_data = (X_val_mlp,Y_val_mlp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "a7sZ1GCkGXZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9886040-a0e8-4241-b75c-3e690360b978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4186 - accuracy: 0.8482\n",
            "\n",
            "MLP Test loss: 0.418639212846756\n",
            "MLP Test accuracy: 0.8482000231742859\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test_mlp, Y_test_mlp, verbose = 1)\n",
        "print()\n",
        "print('MLP Test loss:', score[0])\n",
        "print('MLP Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}